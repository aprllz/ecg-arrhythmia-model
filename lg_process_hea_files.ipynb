{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import os\n",
    "from utils import load_dictionary_from_file\n",
    "#load .hea file\n",
    "file_name = 'data\\ptb-xl\\HR00001.hea'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG CODE - READ FILES\n",
    "\n",
    "with open(file_name, 'r') as file:\n",
    "    main_content = file.read()\n",
    "# look for contains of the file between tag <code> and </code>\n",
    "# and return the first match\n",
    "# match = re.search(r'<code>(.*?)</code>', html_content, re.DOTALL)\n",
    "if main_content:\n",
    "    print(main_content)\n",
    "else:\n",
    "    print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG CODE - MODIFY FILES\n",
    "\n",
    "#append date time to first line of match\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "# print(dt_string)\n",
    "#split the match into lines\n",
    "lines = main_content.split('\\n')\n",
    "#append date time to first line\n",
    "lines[0] = lines[0] + ' ' + dt_string\n",
    "#in the next 12 lines:\n",
    "\n",
    "for i in range(1, 13):\n",
    "    # lines[i] = lines[i][:12] + lines[i][14:] #remove 'x1' after 12th character\n",
    "    # lines[i] = lines[i][:20] + lines[i][25:] #remove '.0(0)' after 20th character\n",
    "    #get location of '.mat' in the line\n",
    "    mat_loc = lines[i].find('.mat')+4 #location id at beginning of '.mat' -> +4 till the end\n",
    "    # print(mat_loc)\n",
    "    lines[i] = lines[i][:mat_loc+3] + lines[i][mat_loc+5:] #remove 'x1' \n",
    "    lines[i] = lines[i][:mat_loc+11] + lines[i][mat_loc+16:] #remove '.0(0)' \n",
    "\n",
    "#in the remaining lines, replace \"#\" with \"# \"\n",
    "for i in range(13, len(lines)):\n",
    "    lines[i] = lines[i].replace('# ', '#')\n",
    "    \n",
    "   \n",
    "#join the lines back together\n",
    "new_content = '\\n'.join(lines)\n",
    "print(new_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. FUNCTION READ, AND MODIFY FILES\n",
    "def process_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        main_content = file.read()\n",
    "    # main_content = re.search(r'<code>(.*?)</code>', main_content, re.DOTALL) #no need to get part of the file     \n",
    "    file.close()\n",
    "    if main_content:\n",
    "        # lines = main_content.group(1).split('\\n')\n",
    "        lines = main_content.split('\\n')\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "        lines[0] = lines[0] + ' ' + dt_string #append date time to first line\n",
    "        for i in range(1, 13):\n",
    "            #get location of '.mat' in the line\n",
    "            mat_loc = lines[i].find('.mat')+4 #location id at beginning of '.mat' -> +4 till the end\n",
    "            # print(mat_loc)\n",
    "            lines[i] = lines[i][:mat_loc+3] + lines[i][mat_loc+5:] #remove 'x1' \n",
    "            lines[i] = lines[i][:mat_loc+11] + lines[i][mat_loc+16:] #remove '.0(0)' \n",
    "        for i in range(13, len(lines)):\n",
    "            lines[i] = lines[i].replace('# ', '#') #replace \"#\" with \"# \" in the remaining lines\n",
    "        new_content = '\\n'.join(lines)\n",
    "        # new_file_name = file_name.replace('.hea', '_new.hea') #no need to change the file name\n",
    "        #overwrite the original file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(new_content)\n",
    "            file.close()\n",
    "        # print('New file created:', file_name)\n",
    "    else:\n",
    "        print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALL manual (read and modify files)\n",
    "#loop through the files in main folder and process each file\n",
    "files = os.listdir('data\\CPSC_2018')\n",
    "#make full path to each file\n",
    "files = [os.path.join('data\\CPSC_2018', file) for file in files]\n",
    "for file in files:\n",
    "    if file.endswith('.hea'):\n",
    "        process_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. FUNCTION MOVE FILES\n",
    "def copy_files(folder, N):\n",
    "    files = os.listdir(folder)\n",
    "    #if N = 0, loop all files\n",
    "    if N == 0:\n",
    "        N = len(files)\n",
    "        \n",
    "    for i in range(N):\n",
    "        file_name = os.path.join(folder, files[i])\n",
    "        new_folder = os.path.dirname(folder) #copy to upper folder\n",
    "        # new_folder = os.path.join(os.path.dirname(folder), 'main-data')\n",
    "        shutil.copy(file_name, new_folder)\n",
    "        # print('Copied:', file_name)\n",
    "    print('Done, ', N, 'files copied in', folder)\n",
    "\n",
    "# copy_files('.\\data\\CPSC_2018\\g1', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. FUNCTION MOVE AND PROCESS FILES\n",
    "\n",
    "def main_hea_process(data_folder, N):\n",
    "    #make a list of sub-folders within the main data folder\n",
    "    folders = os.listdir(data_folder)\n",
    "    #loop through the folders and copy N files from each sub-folder\n",
    "    for folder in folders:\n",
    "        folder_name = os.path.join(data_folder, folder)\n",
    "        if os.path.isdir(folder_name): #filter dirs only\n",
    "            copy_files(folder_name, N)\n",
    "    #loop through the files in main folder and process each file\n",
    "    files = os.listdir(data_folder)\n",
    "    #make full path to each file\n",
    "    files = [os.path.join(data_folder, file) for file in files]\n",
    "    for file in files:\n",
    "        if file.endswith('.hea'):\n",
    "            process_file(file)\n",
    "    print('Done processing folders:', data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define main data folder string\n",
    "data_folder = 'data\\chapman_shaoxing'\n",
    "# 'data\\ptb-xl'\n",
    "# 'data\\cpsc_2018'\n",
    "# 'data\\cpsc_2018_extra'\n",
    "# 'data\\cpsc_processed'\n",
    "\n",
    "#define samples get from each sub-folder\n",
    "N = 0   #sampling files in each sub-folder. \n",
    "        #Total file = N*number of sub-folder\n",
    "        #N=0, get all files in each sub-folder\n",
    "\n",
    "#process the main data folder\n",
    "main_hea_process(data_folder, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to get unique codes from the files\n",
    "\n",
    "def get_unique_dx_code (data_folder):\n",
    "    files = os.listdir(data_folder)\n",
    "    files = [os.path.join(data_folder, file) for file in files]\n",
    "    list_codes = []\n",
    "    for file in files:\n",
    "        if file.endswith('.hea'):\n",
    "            #read 16th line of the file\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                f.close()\n",
    "            #get the 16th line\n",
    "            line = lines[15]\n",
    "            #get text after '#Dx: '\n",
    "            text = line.split('#Dx: ')[1]\n",
    "            #split the text into list of code, delimited by ','\n",
    "            codes = text.split(',')\n",
    "            #remove leading and trailing white spaces from each code\n",
    "            codes = [code.strip() for code in codes]\n",
    "            #append unique codes to the list\n",
    "            for code in codes:\n",
    "                if code not in list_codes:\n",
    "                    list_codes.append(code)\n",
    "    return list_codes\n",
    "\n",
    "#call the function\n",
    "# data_folder = 'data\\cpsc_2018'\n",
    "list_codes = get_unique_dx_code(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to load dictionary from file\n",
    "def load_dictionary_from_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        dictionary = json.load(file)\n",
    "    return dictionary\n",
    "\n",
    "# Function to store dictionary to file\n",
    "def store_dictionary_to_file(dictionary, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of dx_dict file and class_labels file\n",
    "file_dx_name = 'meta_data\\dx_dict.json'  # File name to store the dictionary dx_dict\n",
    "file_class_name = 'meta_data\\class_labels.txt' # File name to store the class labels\n",
    "\n",
    "# if dx_dict can be loaded from file, then load it, else use default dx_dict\n",
    "if os.path.exists(file_dx_name):\n",
    "    dx_dict = load_dictionary_from_file(file_dx_name)\n",
    "else:\n",
    "    #introduce dx_dict to store the codes\n",
    "    dx_dict = {\n",
    "            '426783006': 'SNR', # Normal sinus rhythm\n",
    "            '164889003': 'AF', # Atrial fibrillation\n",
    "            '270492004': 'IAVB', # First-degree atrioventricular block\n",
    "            '164909002': 'LBBB', # Left bundle branch block\n",
    "            '713427006': 'RBBB', # Complete right bundle branch block\n",
    "            '59118001': 'RBBB', # Right bundle branch block\n",
    "            '284470004': 'PAC', # Premature atrial contraction\n",
    "            '63593006': 'PAC', # Supraventricular premature beats\n",
    "            '164884008': 'PVC', # Ventricular ectopics\n",
    "            '429622005': 'STD', # ST-segment depression\n",
    "            '164931005': 'STE', # ST-segment elevation\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the codes to the dictionary\n",
    "for code in list_codes:    \n",
    "    if code not in dx_dict:\n",
    "        # print('New code found:', code)\n",
    "        #introduce new id sequence for new codes\n",
    "        seq = 'Other' + str(len(dx_dict)-11+1) #original codes are 11\n",
    "        dx_dict[code] = seq\n",
    "# print(dx_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplicate codes in dx_dict\n",
    "\n",
    "#make a list of codes\n",
    "codes = list(dx_dict.keys())\n",
    "#make a list of unique codes\n",
    "unique_codes = list(set(codes))\n",
    "#check if the length of the two lists are the same\n",
    "if len(codes) == len(unique_codes):\n",
    "    print('No duplicate codes')\n",
    "else:\n",
    "    print('Duplicate codes found')\n",
    "    #loop through the unique codes\n",
    "    for code in unique_codes:\n",
    "        #count the number of times the code appears in the list of codes\n",
    "        count = codes.count(code)\n",
    "        #if the count is greater than 1, print the code and the count\n",
    "        if count > 1:\n",
    "            print(code, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store new dx_dict to file\n",
    "dx_dict = {\n",
    "    '426783006': 'SNR', # Normal sinus rhythm\n",
    "    '164889003': 'AF', # Atrial fibrillation\n",
    "    '270492004': 'IAVB', # First-degree atrioventricular block\n",
    "    '164909002': 'LBBB', # Left bundle branch block\n",
    "    '713427006': 'RBBB', # Complete right bundle branch block\n",
    "    '59118001': 'RBBB', # Right bundle branch block\n",
    "    '284470004': 'PAC', # Premature atrial contraction\n",
    "    '63593006': 'PAC', # Supraventricular premature beats\n",
    "    '164884008': 'PVC', # Ventricular ectopics\n",
    "    '429622005': 'STD', # ST-segment depression\n",
    "    '164931005': 'STE', # ST-segment elevation\n",
    "}\n",
    "# filename = os.path.join(data_folder, filename)\n",
    "store_dictionary_to_file(dx_dict, file_dx_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to make class labels from the dictionary\n",
    "\n",
    "#function to get unique values from the dictionary -> as class labels\n",
    "def get_unique_values(dictionary):\n",
    "    values = list(dictionary.values())\n",
    "    unique_values = list(set(values))\n",
    "    return unique_values\n",
    "\n",
    "#function to store unique values to file\n",
    "def store_class_label_to_file(values, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for value in values:\n",
    "            file.write(value + '\\n')\n",
    "        file.close()\n",
    "\n",
    "#function to load unique values from file and store in a list\n",
    "def load_class_label_from_file(filename):\n",
    "    class_label = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            class_label.append(line.strip())\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_class_name = 'meta_data\\class_labels.txt' # File name to store the class labels\n",
    "#get class labels from dictionary\n",
    "\n",
    "class_labels = get_unique_values(dx_dict)\n",
    "#store class labels to file\n",
    "store_class_label_to_file(class_labels, file_class_name)\n",
    "\n",
    "#load dict back to file\n",
    "#dictionary = load_dictionary_from_file(filename)\n",
    "#load class labels back to file\n",
    "#class_labels = load_class_label_from_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dict back to file\n",
    "dictionary = load_dictionary_from_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to execute the above functions\n",
    "\n",
    "# 'data\\ptb-xl'\n",
    "# 'data\\cpsc_2018'\n",
    "# 'data\\cpsc_2018_extra'\n",
    "# 'data\\cpsc_processed'\n",
    "\n",
    "\n",
    "#python preprocess.py --data-dir 'data\\cpsc_2018_extra'\n",
    "#python baselines.py --data-dir 'data\\cpsc_2018_extra'  --classifier 'LR'\n",
    "#python main.py --data-dir 'data\\ptb-xl' --leads 'all' --epochs 2 --use-gpu --batch-size 200\n",
    "#python predict.py --data-dir \"data\\cpsc_processed\" --leads 'all' --use-gpu --batch-size 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def function to move files .hea and .mat from one folder to another. \n",
    "#Files name are extracted from 1st column of df\n",
    "def move_files(df, source_folder, dest_folder):\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = row['File']\n",
    "        #append '.hea' and '.mat' to the file name, and move the files, one by one\n",
    "        for ext in ['.hea', '.mat']:\n",
    "            source_file = os.path.join(source_folder, file_name + ext)\n",
    "            dest_file = os.path.join(dest_folder, file_name + ext)\n",
    "            shutil.move(source_file, dest_file)\n",
    "    print('Done moving files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"preprocess.py\" --data-dir \"data\\train_dataset\"\n",
    "#run function move file and handle .hea files\n",
    "# %run \"preprocess.py\" --data-dir \"data\\chapman_shaoxing\"\n",
    "# %run \"preprocess.py\" --data-dir \"data\\test_dataset\"\n",
    "# %run \"baselines.py\" --data-dir \"data\\train_dataset\" --classifier \"LR\"\n",
    "%run \"main.py\" --data-dir \"data\\cpsc_2018_extra\" --leads 'all' --epochs 1 --batch-size 200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
