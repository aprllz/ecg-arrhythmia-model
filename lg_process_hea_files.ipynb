{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128979,"status":"ok","timestamp":1719914374127,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"lpahMXFy7rkj","outputId":"e9573654-c472-4004-ab59-b8991549d726"},"outputs":[],"source":["#### FOR ACADEMIC PROJECT WORK\n","#check if lib install or not, if not, install\n","\n","# !pip install wfdb\n","# !pip install lightgbm\n","# !pip install PyWavelets\n","# !pip install biosppy\n","# !pip install torch\n","# !pip install shap"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[H\u001b[2JCurrent time: 2024-07-10 17:49:03\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:49:33\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:50:03\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:50:33\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:51:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:51:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:52:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:52:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:53:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:53:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:54:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:54:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:55:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:55:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:56:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:56:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:57:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:57:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:58:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:58:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:59:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 17:59:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:00:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:00:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:01:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:01:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:02:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:02:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:03:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:03:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:04:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:04:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:05:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:05:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:06:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:06:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:07:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:07:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:08:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:08:34\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:09:04\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:09:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:10:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:10:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:11:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:11:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:12:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:12:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:13:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:13:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:14:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:14:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:15:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:15:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:16:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:16:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:17:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:17:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:18:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:18:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:19:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:19:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:20:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:20:35\n","Current time: 2024-07-10 18:21:05\n","\u001b[H\u001b[2J\u001b[H\u001b[2JCurrent time: 2024-07-10 18:21:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:22:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:22:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:23:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:23:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:24:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:24:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:25:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:25:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:26:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:26:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:27:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:27:35\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:28:05\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:28:36\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:29:06\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:29:36\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:30:06\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:30:36\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:31:06\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:31:36\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:32:06\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:32:36\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:33:06\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:33:36\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:34:06\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:34:37\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:35:07\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:35:37\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:36:07\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:36:37\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:37:07\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:37:37\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:38:07\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:38:37\n","\u001b[H\u001b[2JCurrent time: 2024-07-10 18:39:07\n"]}],"source":["#keep updating progress and output as time goes by\n","import time\n","import os\n","\n","def update_terminal():\n","    while True:\n","        # Clear jupyter notebook output\n","        os.system('clear')\n","\n","        # Get the current time\n","        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n","\n","        # Print the current time\n","        print(f\"Current time: {current_time}\")\n","\n","        # Wait for 10 seconds before updating again\n","        time.sleep(30)\n","\n","if __name__ == \"__main__\":\n","    update_terminal()\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of files in each folder\n","cpsc_processed: 13757\n","train_dataset: 23320\n","test_dataset: 9248\n"]}],"source":["\n","import os\n","#check number of files exist in each data folders\n","print('Number of files in each folder')\n","print('cpsc_processed:', len(os.listdir('/workspaces/ecg-arrhythmia-model/data/cpsc_processed')))\n","print('train_dataset:', len(os.listdir('/workspaces/ecg-arrhythmia-model/data/train_dataset')))\n","print('test_dataset:', len(os.listdir('/workspaces/ecg-arrhythmia-model/data/test_dataset')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3793,"status":"ok","timestamp":1719915071180,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"CyFOQQOw7yrP","outputId":"2eb51e77-c6e4-46ed-8e10-27ee789e95e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# from google.colab import drive\n","# drive.mount(\"/content/drive\", force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2nsABKYd71cj"},"outputs":[],"source":["# #set working directory to this folder\n","# import os...............\n","# os.chdir('/content/drive/Othercomputers/My Laptop/ecg-arrhythmia-model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Qq6vcDW7qE2"},"outputs":[],"source":["import re\n","from datetime import datetime\n","import shutil\n","import os\n","from utils import load_dictionary_from_file\n","#load .hea file\n","file_name = 'data\\ptb-xl\\HR00001.hea'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OrPV-eoT7qE3"},"outputs":[],"source":["# DEBUG CODE - READ FILES\n","\n","with open(file_name, 'r') as file:\n","    main_content = file.read()\n","# look for contains of the file between tag <code> and </code>\n","# and return the first match\n","# match = re.search(r'<code>(.*?)</code>', html_content, re.DOTALL)\n","if main_content:\n","    print(main_content)\n","else:\n","    print('No match')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpvNDe7Z7qE3"},"outputs":[],"source":["# DEBUG CODE - MODIFY FILES\n","\n","#append date time to first line of match\n","from datetime import datetime\n","now = datetime.now()\n","dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n","# print(dt_string)\n","#split the match into lines\n","lines = main_content.split('\\n')\n","#append date time to first line\n","lines[0] = lines[0] + ' ' + dt_string\n","#in the next 12 lines:\n","\n","for i in range(1, 13):\n","    # lines[i] = lines[i][:12] + lines[i][14:] #remove 'x1' after 12th character\n","    # lines[i] = lines[i][:20] + lines[i][25:] #remove '.0(0)' after 20th character\n","    #get location of '.mat' in the line\n","    mat_loc = lines[i].find('.mat')+4 #location id at beginning of '.mat' -> +4 till the end\n","    # print(mat_loc)\n","    lines[i] = lines[i][:mat_loc+3] + lines[i][mat_loc+5:] #remove 'x1'\n","    lines[i] = lines[i][:mat_loc+11] + lines[i][mat_loc+16:] #remove '.0(0)'\n","\n","#in the remaining lines, replace \"#\" with \"# \"\n","for i in range(13, len(lines)):\n","    lines[i] = lines[i].replace('# ', '#')\n","\n","\n","#join the lines back together\n","new_content = '\\n'.join(lines)\n","print(new_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uTAJ8Ujv7qE4"},"outputs":[],"source":["#1. FUNCTION READ, AND MODIFY FILES\n","def process_file(file_name):\n","    with open(file_name, 'r') as file:\n","        main_content = file.read()\n","    # main_content = re.search(r'<code>(.*?)</code>', main_content, re.DOTALL) #no need to get part of the file\n","    file.close()\n","    if main_content:\n","        # lines = main_content.group(1).split('\\n')\n","        lines = main_content.split('\\n')\n","        now = datetime.now()\n","        dt_string = now.strftime(\"%d-%b-%Y %H:%M:%S\")\n","        lines[0] = lines[0] + ' ' + dt_string #append date time to first line\n","        for i in range(1, 13):\n","            #get location of '.mat' in the line\n","            mat_loc = lines[i].find('.mat')+4 #location id at beginning of '.mat' -> +4 till the end\n","            # print(mat_loc)\n","            lines[i] = lines[i][:mat_loc+3] + lines[i][mat_loc+5:] #remove 'x1'\n","            lines[i] = lines[i][:mat_loc+11] + lines[i][mat_loc+16:] #remove '.0(0)'\n","        for i in range(13, len(lines)):\n","            lines[i] = lines[i].replace('# ', '#') #replace \"#\" with \"# \" in the remaining lines\n","        new_content = '\\n'.join(lines)\n","        # new_file_name = file_name.replace('.hea', '_new.hea') #no need to change the file name\n","        #overwrite the original file\n","        with open(file_name, 'w') as file:\n","            file.write(new_content)\n","            file.close()\n","        # print('New file created:', file_name)\n","    else:\n","        print('No match')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbZxi-4_7qE4"},"outputs":[],"source":["# CALL manual (read and modify files)\n","#loop through the files in main folder and process each file\n","files = os.listdir('data\\CPSC_2018')\n","#make full path to each file\n","files = [os.path.join('data\\CPSC_2018', file) for file in files]\n","for file in files:\n","    if file.endswith('.hea'):\n","        process_file(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhYywZz17qE4"},"outputs":[],"source":["#2. FUNCTION MOVE FILES\n","def copy_files(folder, N):\n","    files = os.listdir(folder)\n","    #if N = 0, loop all files\n","    if N == 0:\n","        N = len(files)\n","\n","    for i in range(N):\n","        file_name = os.path.join(folder, files[i])\n","        new_folder = os.path.dirname(folder) #copy to upper folder\n","        # new_folder = os.path.join(os.path.dirname(folder), 'main-data')\n","        shutil.copy(file_name, new_folder)\n","        # print('Copied:', file_name)\n","    print('Done, ', N, 'files copied in', folder)\n","\n","# copy_files('.\\data\\CPSC_2018\\g1', 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mllEww2Y7qE4"},"outputs":[],"source":["#3. FUNCTION MOVE AND PROCESS FILES\n","\n","def main_hea_process(data_folder, N):\n","    #make a list of sub-folders within the main data folder\n","    folders = os.listdir(data_folder)\n","    #loop through the folders and copy N files from each sub-folder\n","    for folder in folders:\n","        folder_name = os.path.join(data_folder, folder)\n","        if os.path.isdir(folder_name): #filter dirs only\n","            copy_files(folder_name, N)\n","    #loop through the files in main folder and process each file\n","    files = os.listdir(data_folder)\n","    #make full path to each file\n","    files = [os.path.join(data_folder, file) for file in files]\n","    for file in files:\n","        if file.endswith('.hea'):\n","            process_file(file)\n","    print('Done processing folders:', data_folder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-RSU2hU7qE4"},"outputs":[],"source":["#define main data folder string\n","data_folder = 'data\\chapman_shaoxing'\n","# 'data\\ptb-xl'\n","# 'data\\cpsc_2018'\n","# 'data\\cpsc_2018_extra'\n","# 'data\\cpsc_processed'\n","\n","#define samples get from each sub-folder\n","N = 0   #sampling files in each sub-folder.\n","        #Total file = N*number of sub-folder\n","        #N=0, get all files in each sub-folder\n","\n","#process the main data folder\n","main_hea_process(data_folder, N)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YhJ4dQ_7qE4"},"outputs":[],"source":["#Utility function to get unique codes from the files\n","\n","def get_unique_dx_code (data_folder):\n","    files = os.listdir(data_folder)\n","    files = [os.path.join(data_folder, file) for file in files]\n","    list_codes = []\n","    for file in files:\n","        if file.endswith('.hea'):\n","            #read 16th line of the file\n","            with open(file, 'r') as f:\n","                lines = f.readlines()\n","                f.close()\n","            #get the 16th line\n","            line = lines[15]\n","            #get text after '#Dx: '\n","            text = line.split('#Dx: ')[1]\n","            #split the text into list of code, delimited by ','\n","            codes = text.split(',')\n","            #remove leading and trailing white spaces from each code\n","            codes = [code.strip() for code in codes]\n","            #append unique codes to the list\n","            for code in codes:\n","                if code not in list_codes:\n","                    list_codes.append(code)\n","    return list_codes\n","\n","#call the function\n","# data_folder = 'data\\cpsc_2018'\n","list_codes = get_unique_dx_code(data_folder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9_a_VF_7qE5"},"outputs":[],"source":["import json\n","\n","# Function to load dictionary from file\n","def load_dictionary_from_file(filename):\n","    with open(filename, 'r') as file:\n","        dictionary = json.load(file)\n","    return dictionary\n","\n","# Function to store dictionary to file\n","def store_dictionary_to_file(dictionary, filename):\n","    with open(filename, 'w') as file:\n","        json.dump(dictionary, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45O7Wmhd7qE5"},"outputs":[],"source":["# location of dx_dict file and class_labels file\n","file_dx_name = 'meta_data\\dx_dict.json'  # File name to store the dictionary dx_dict\n","file_class_name = 'meta_data\\class_labels.txt' # File name to store the class labels\n","\n","# if dx_dict can be loaded from file, then load it, else use default dx_dict\n","if os.path.exists(file_dx_name):\n","    dx_dict = load_dictionary_from_file(file_dx_name)\n","else:\n","    #introduce dx_dict to store the codes\n","    dx_dict = {\n","            '426783006': 'SNR', # Normal sinus rhythm\n","            '164889003': 'AF', # Atrial fibrillation\n","            '270492004': 'IAVB', # First-degree atrioventricular block\n","            '164909002': 'LBBB', # Left bundle branch block\n","            '713427006': 'RBBB', # Complete right bundle branch block\n","            '59118001': 'RBBB', # Right bundle branch block\n","            '284470004': 'PAC', # Premature atrial contraction\n","            '63593006': 'PAC', # Supraventricular premature beats\n","            '164884008': 'PVC', # Ventricular ectopics\n","            '429622005': 'STD', # ST-segment depression\n","            '164931005': 'STE', # ST-segment elevation\n","        }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9Rb7XLA7qE5"},"outputs":[],"source":["#append the codes to the dictionary\n","for code in list_codes:\n","    if code not in dx_dict:\n","        # print('New code found:', code)\n","        #introduce new id sequence for new codes\n","        seq = 'Other' + str(len(dx_dict)-11+1) #original codes are 11\n","        dx_dict[code] = seq\n","# print(dx_dict)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbJymajf7qE5"},"outputs":[],"source":["#check duplicate codes in dx_dict\n","\n","#make a list of codes\n","codes = list(dx_dict.keys())\n","#make a list of unique codes\n","unique_codes = list(set(codes))\n","#check if the length of the two lists are the same\n","if len(codes) == len(unique_codes):\n","    print('No duplicate codes')\n","else:\n","    print('Duplicate codes found')\n","    #loop through the unique codes\n","    for code in unique_codes:\n","        #count the number of times the code appears in the list of codes\n","        count = codes.count(code)\n","        #if the count is greater than 1, print the code and the count\n","        if count > 1:\n","            print(code, count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zSsuv7K7qE5"},"outputs":[],"source":["# store new dx_dict to file\n","dx_dict = {\n","    '426783006': 'SNR', # Normal sinus rhythm\n","    '164889003': 'AF', # Atrial fibrillation\n","    '270492004': 'IAVB', # First-degree atrioventricular block\n","    '164909002': 'LBBB', # Left bundle branch block\n","    '713427006': 'RBBB', # Complete right bundle branch block\n","    '59118001': 'RBBB', # Right bundle branch block\n","    '284470004': 'PAC', # Premature atrial contraction\n","    '63593006': 'PAC', # Supraventricular premature beats\n","    '164884008': 'PVC', # Ventricular ectopics\n","    '429622005': 'STD', # ST-segment depression\n","    '164931005': 'STE', # ST-segment elevation\n","}\n","# filename = os.path.join(data_folder, filename)\n","store_dictionary_to_file(dx_dict, file_dx_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJFNo_HS7qE5"},"outputs":[],"source":["#define function to make class labels from the dictionary\n","\n","#function to get unique values from the dictionary -> as class labels\n","def get_unique_values(dictionary):\n","    values = list(dictionary.values())\n","    unique_values = list(set(values))\n","    return unique_values\n","\n","#function to store unique values to file\n","def store_class_label_to_file(values, filename):\n","    with open(filename, 'w') as file:\n","        for value in values:\n","            file.write(value + '\\n')\n","        file.close()\n","\n","#function to load unique values from file and store in a list\n","def load_class_label_from_file(filename):\n","    class_label = []\n","    with open(filename, 'r') as file:\n","        for line in file:\n","            class_label.append(line.strip())\n","    return class_label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0xy3qTW7qE5"},"outputs":[],"source":["file_class_name = 'meta_data\\class_labels.txt' # File name to store the class labels\n","#get class labels from dictionary\n","\n","class_labels = get_unique_values(dx_dict)\n","#store class labels to file\n","store_class_label_to_file(class_labels, file_class_name)\n","\n","#load dict back to file\n","#dictionary = load_dictionary_from_file(filename)\n","#load class labels back to file\n","#class_labels = load_class_label_from_file(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MLqtpx_7qE7"},"outputs":[],"source":["#load dict back to file\n","dictionary = load_dictionary_from_file(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OY7-gbv17qE7"},"outputs":[],"source":["#Script to execute the above functions\n","\n","# 'data\\ptb-xl'\n","# 'data\\cpsc_2018'\n","# 'data\\cpsc_2018_extra'\n","# 'data\\cpsc_processed'\n","\n","\n","#python preprocess.py --data-dir 'data\\cpsc_2018_extra'\n","#python baselines.py --data-dir 'data\\cpsc_2018_extra'  --classifier 'LR'\n","#python main.py --data-dir 'data\\ptb-xl' --leads 'all' --epochs 2 --use-gpu --batch-size 200\n","#python predict.py --data-dir \"data\\cpsc_processed\" --leads 'all' --use-gpu --batch-size 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w10Gqq7J7qE7"},"outputs":[],"source":["#def function to move files .hea and .mat from one folder to another.\n","#Files name are extracted from 1st column of df\n","def move_files(df, source_folder, dest_folder):\n","    for index, row in df.iterrows():\n","        file_name = row['File']\n","        #append '.hea' and '.mat' to the file name, and move the files, one by one\n","        for ext in ['.hea', '.mat']:\n","            source_file = os.path.join(source_folder, file_name + ext)\n","            dest_file = os.path.join(dest_folder, file_name + ext)\n","            shutil.move(source_file, dest_file)\n","    print('Done moving files')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15477366,"status":"ok","timestamp":1719831334223,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"1ymPHald7qE8","outputId":"91fcae94-e68f-43d4-ba41-73d087dc9c14"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of keep records: 27823 Number of results: 27823 Percentage of keep records: 100.0\n"]}],"source":["# %run \"preprocess.py\" --data-dir \"data/cpsc_processed\" -- done in full\n","# %run \"preprocess.py\" --data-dir \"data/train_dataset\" -- done in full\n","\n","#run function move file and handle .hea files\n","# %run \"preprocess.py\" --data-dir \"data\\chapman_shaoxing\"\n","# %run \"preprocess.py\" --data-dir \"data\\test_dataset\"\n","# %run \"baselines.py\" --data-dir \"data\\train_dataset\" --classifier 'all'\n","# %run \"main.py\" --data-dir \"data\\cpsc_2018_extra\" --leads 'all' --epochs 1 --batch-size 200"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11430211,"status":"ok","timestamp":1719845079614,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"Kj_jtXsmEcXd","outputId":"b6b6ccd3-cd0a-41da-f503-303e6e769fcf"},"outputs":[{"name":"stdout","output_type":"stream","text":["data/cpsc_processed/labels.csv\n","Generating expert features...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6877/6877 [2:58:30<00:00,  1.56s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Start training LR...\n","Finding optimal thresholds on validation dataset...\n","LR F1s: [0.27467811158798283, 0.8108108108108107, 0.8333333333333334, 0.5037037037037038, 0.4673913043478261, 0.6614785992217898, 0.35114503816793896, 0.3, 0.609053497942387]\n","Avg F1: 0.5346215999017525\n","Start training RF...\n","Finding optimal thresholds on validation dataset...\n","RF F1s: [0.3218390804597701, 0.8, 0.9142857142857143, 0.5283018867924528, 0.586046511627907, 0.6733333333333333, 0.3438914027149321, 0.3939393939393939, 0.6]\n","Avg F1: 0.573515258128167\n","Start training LGB...\n","[LightGBM] [Info] Number of positive: 481, number of negative: 5022\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106001 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.087407 -> initscore=-2.345716\n","[LightGBM] [Info] Start training from score -2.345716\n","[LightGBM] [Info] Number of positive: 1486, number of negative: 4017\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095689 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.270035 -> initscore=-0.994447\n","[LightGBM] [Info] Start training from score -0.994447\n","[LightGBM] [Info] Number of positive: 198, number of negative: 5305\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102300 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035980 -> initscore=-3.288138\n","[LightGBM] [Info] Start training from score -3.288138\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 565, number of negative: 4938\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053771 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102671 -> initscore=-2.167890\n","[LightGBM] [Info] Start training from score -2.167890\n","[LightGBM] [Info] Number of positive: 694, number of negative: 4809\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054682 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.126113 -> initscore=-1.935772\n","[LightGBM] [Info] Start training from score -1.935772\n","[LightGBM] [Info] Number of positive: 984, number of negative: 4519\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058147 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.178812 -> initscore=-1.524420\n","[LightGBM] [Info] Start training from score -1.524420\n","[LightGBM] [Info] Number of positive: 583, number of negative: 4920\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057667 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.105942 -> initscore=-2.132877\n","[LightGBM] [Info] Start training from score -2.132877\n","[LightGBM] [Info] Number of positive: 181, number of negative: 5322\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053984 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032891 -> initscore=-3.381107\n","[LightGBM] [Info] Start training from score -3.381107\n","[LightGBM] [Info] Number of positive: 719, number of negative: 4784\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057065 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 160462\n","[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.130656 -> initscore=-1.895171\n","[LightGBM] [Info] Start training from score -1.895171\n","Finding optimal thresholds on validation dataset...\n","LGB F1s: [0.2923076923076923, 0.8225806451612904, 0.9411764705882353, 0.6153846153846153, 0.6794258373205742, 0.7500000000000001, 0.481203007518797, 0.5098039215686274, 0.5833333333333334]\n","Avg F1: 0.6305795025759072\n","Start training MLP...\n","Finding optimal thresholds on validation dataset...\n","MLP F1s: [0.3043478260869565, 0.8254847645429363, 0.787878787878788, 0.5401459854014599, 0.5945945945945946, 0.7510917030567685, 0.4108108108108109, 0.34285714285714286, 0.5873015873015873]\n","Avg F1: 0.571612578059005\n"]}],"source":["%run \"baselines.py\" --data-dir \"data/cpsc_processed\" --classifier 'all'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21186227,"status":"ok","timestamp":1719882929512,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"YBgZml7ZBBWg","outputId":"834cd20e-e1bf-448e-b99c-1285b68f652c"},"outputs":[{"name":"stdout","output_type":"stream","text":["data/train_dataset/labels.csv\n","Generating expert features...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 27823/27823 [5:12:40<00:00,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Start training LR...\n","Finding optimal thresholds on validation dataset...\n","LR F1s: [0.14342629482071714, 0.7941787941787942, 0.8414634146341463, 0.5059101654846335, 0.295, 0.5485519591141398, 0.22141560798548096, 0.29268292682926833, 0.9107049608355091]\n","Avg F1: 0.5059260137647432\n","Start training RF...\n","Finding optimal thresholds on validation dataset...\n","RF F1s: [0.17194570135746606, 0.8353413654618475, 0.8502994011976047, 0.46265060240963857, 0.38674033149171266, 0.6140089418777943, 0.2887139107611548, 0.4736842105263157, 0.9322381930184805]\n","Avg F1: 0.5572914064557793\n","Start training LGB...\n","[LightGBM] [Info] Number of positive: 1053, number of negative: 21204\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.234394 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047311 -> initscore=-3.002547\n","[LightGBM] [Info] Start training from score -3.002547\n","[LightGBM] [Info] Number of positive: 2018, number of negative: 20239\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.245410 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.090668 -> initscore=-2.305505\n","[LightGBM] [Info] Start training from score -2.305505\n","[LightGBM] [Info] Number of positive: 648, number of negative: 21609\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.438520 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.029114 -> initscore=-3.506974\n","[LightGBM] [Info] Start training from score -3.506974\n","[LightGBM] [Info] Number of positive: 1454, number of negative: 20803\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.269688 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065328 -> initscore=-2.660779\n","[LightGBM] [Info] Start training from score -2.660779\n","[LightGBM] [Info] Number of positive: 1555, number of negative: 20702\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.258912 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.069866 -> initscore=-2.588755\n","[LightGBM] [Info] Start training from score -2.588755\n","[LightGBM] [Info] Number of positive: 2286, number of negative: 19971\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.259617 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.102709 -> initscore=-2.167478\n","[LightGBM] [Info] Start training from score -2.167478\n","[LightGBM] [Info] Number of positive: 1290, number of negative: 20967\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.266703 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.057959 -> initscore=-2.788308\n","[LightGBM] [Info] Start training from score -2.788308\n","[LightGBM] [Info] Number of positive: 258, number of negative: 21999\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.419860 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011592 -> initscore=-4.445793\n","[LightGBM] [Info] Start training from score -4.445793\n","[LightGBM] [Info] Number of positive: 15226, number of negative: 7031\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.282315 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 161751\n","[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.684099 -> initscore=0.772676\n","[LightGBM] [Info] Start training from score 0.772676\n","Finding optimal thresholds on validation dataset...\n","LGB F1s: [0.15217391304347827, 0.8798449612403101, 0.8466257668711655, 0.580188679245283, 0.47058823529411764, 0.7033639143730888, 0.2402826855123675, 0.4150943396226415, 0.9435630689206762]\n","Avg F1: 0.5813028404581254\n","Start training MLP...\n","Finding optimal thresholds on validation dataset...\n","MLP F1s: [0.18390804597701152, 0.8435114503816795, 0.7951807228915663, 0.6142857142857143, 0.40109890109890106, 0.6123893805309734, 0.2491803278688524, 0.46875, 0.9230369214768591]\n","Avg F1: 0.5657046071679509\n"]}],"source":["%run \"baselines.py\" --data-dir \"data/train_dataset\" --classifier 'all'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8298817,"status":"ok","timestamp":1719911814058,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"85gpnHUPALkn","outputId":"e5e0a1b9-954e-47b5-e095-53b05d03db7e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 0:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv1d(input, weight, bias, self.stride,\n","/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","100%|██████████| 344/344 [38:21<00:00,  6.69s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 110.4297\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [04:50<00:00,  6.75s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 10.0407\n","F1s: [0.64197531 0.66409266 0.4494382  0.88372093 0.87594937 0.384\n"," 0.65771812 0.43514644 0.28571429]\n","Avg F1: 0.5864\n","Training epoch 1:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:08<00:00,  2.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 74.6370\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 8.0455\n","F1s: [0.68518519 0.72972973 0.56774194 0.93333333 0.91919192 0.49056604\n"," 0.69117647 0.57004831 0.36363636]\n","Avg F1: 0.6612\n","Training epoch 2:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 55.7151\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:08<00:00,  5.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.0548\n","F1s: [0.78378378 0.88715953 0.87837838 0.97674419 0.92620865 0.54700855\n"," 0.74626866 0.8        0.5625    ]\n","Avg F1: 0.7898\n","Training epoch 3:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 45.3226\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:08<00:00,  4.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.0414\n","F1s: [0.8042328  0.92369478 0.90666667 0.97674419 0.9151671  0.61682243\n"," 0.76119403 0.79012346 0.53846154]\n","Avg F1: 0.8037\n","Training epoch 4:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 41.9740\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.0832\n","F1s: [0.8042328  0.92       0.91275168 0.97674419 0.91484185 0.61682243\n"," 0.76422764 0.82716049 0.55172414]\n","Avg F1: 0.8098\n","Training epoch 5:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:12<00:00,  2.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 38.4653\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.6021\n","F1s: [0.85294118 0.93650794 0.89855072 1.         0.915      0.67256637\n"," 0.79194631 0.81521739 0.66666667]\n","Avg F1: 0.8388\n","Training epoch 6:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 37.6595\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.0100\n","F1s: [0.79820628 0.94308943 0.90780142 0.95652174 0.91603053 0.6557377\n"," 0.77464789 0.8447205  0.66666667]\n","Avg F1: 0.8293\n","AUCs: [0.97334147 0.98806435 0.99298061 0.99972659 0.98036078 0.93444723\n"," 0.94973767 0.97127223 0.93293651]\n","Avg AUC: 0.9692\n","Training epoch 7:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 35.1155\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.1112\n","F1s: [0.85       0.936      0.90780142 0.97674419 0.91484185 0.67768595\n"," 0.78082192 0.81045752 0.68571429]\n","Avg F1: 0.8378\n","AUCs: [0.98216784 0.98780488 0.99544997 0.99972659 0.98192984 0.95279866\n"," 0.96265597 0.97568888 0.93005952]\n","Avg AUC: 0.9743\n","Training epoch 8:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:12<00:00,  2.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 32.7778\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:10<00:00,  4.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.5994\n","F1s: [0.81553398 0.95081967 0.91025641 0.97674419 0.92345679 0.62015504\n"," 0.79411765 0.80924855 0.69230769]\n","Avg F1: 0.8325\n","AUCs: [0.97615801 0.98670934 0.9969133  0.98591934 0.98315599 0.93519911\n"," 0.9547639  0.97480946 0.96269841]\n","Avg AUC: 0.9729\n","Training epoch 9:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 32.2639\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.1475\n","F1s: [0.82587065 0.94308943 0.90666667 0.97674419 0.92079208 0.68421053\n"," 0.80519481 0.85380117 0.64516129]\n","Avg F1: 0.8402\n","Training epoch 10:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 30.4427\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.6812\n","F1s: [0.84615385 0.9516129  0.93055556 0.97674419 0.92424242 0.68965517\n"," 0.80851064 0.83229814 0.76923077]\n","Avg F1: 0.8588\n","Training epoch 11:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:12<00:00,  2.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 29.0916\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.1866\n","F1s: [0.83168317 0.94262295 0.91666667 0.95238095 0.91666667 0.66666667\n"," 0.78947368 0.83333333 0.74074074]\n","Avg F1: 0.8434\n","AUCs: [0.98189875 0.98882835 0.99677611 0.99945318 0.98306247 0.94750766\n"," 0.96814514 0.97709595 0.96081349]\n","Avg AUC: 0.9782\n","Training epoch 12:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:11<00:00,  2.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 27.4248\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.3034\n","F1s: [0.84057971 0.94308943 0.95104895 0.97674419 0.925      0.71544715\n"," 0.80821918 0.82352941 0.72      ]\n","Avg F1: 0.8560\n","AUCs: [0.98371067 0.9870553  0.99823944 0.99897471 0.9810362  0.9566973\n"," 0.97116529 0.97303107 0.95039683]\n","Avg AUC: 0.9778\n","Training epoch 13:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 25.8951\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.3935\n","F1s: [0.84422111 0.96356275 0.95104895 0.97674419 0.9193154  0.73770492\n"," 0.78431373 0.8125     0.55172414]\n","Avg F1: 0.8379\n","AUCs: [0.97820315 0.98799227 0.99835376 0.99815448 0.98098425 0.95210248\n"," 0.96012081 0.97101817 0.92668651]\n","Avg AUC: 0.9726\n","Training epoch 14:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 23.6817\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.3399\n","F1s: [0.85263158 0.94736842 0.9037037  0.97674419 0.91457286 0.72\n"," 0.7972973  0.81927711 0.68421053]\n","Avg F1: 0.8462\n","AUCs: [0.98024829 0.98894367 0.99364368 0.9961039  0.98136872 0.95037594\n"," 0.97224549 0.97387141 0.97043651]\n","Avg AUC: 0.9786\n","Training epoch 15:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:12<00:00,  2.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 22.9097\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:08<00:00,  5.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.7418\n","F1s: [0.78021978 0.95901639 0.90076336 0.97674419 0.9127182  0.71875\n"," 0.82269504 0.79096045 0.78571429]\n","Avg F1: 0.8497\n","AUCs: [0.96004808 0.98903016 0.9965932  0.99965824 0.98225196 0.95463659\n"," 0.97321547 0.96353332 0.93521825]\n","Avg AUC: 0.9727\n","Training epoch 16:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:11<00:00,  2.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 21.2949\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:08<00:00,  5.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.5562\n","F1s: [0.84042553 0.96721311 0.93243243 0.97674419 0.92268041 0.72\n"," 0.81751825 0.8313253  0.66666667]\n","Avg F1: 0.8528\n","AUCs: [0.97906426 0.9895491  0.99785074 0.99917977 0.98004905 0.95332776\n"," 0.97012918 0.97713504 0.9327381 ]\n","Avg AUC: 0.9754\n","Training epoch 17:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:11<00:00,  2.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 20.4243\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:08<00:00,  4.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.5865\n","F1s: [0.82926829 0.94605809 0.93617021 0.97674419 0.91811414 0.75\n"," 0.82191781 0.82926829 0.54054054]\n","Avg F1: 0.8387\n","AUCs: [0.9791719  0.9877328  0.99814798 0.99938483 0.98143107 0.94619883\n"," 0.96988669 0.97334376 0.93125   ]\n","Avg AUC: 0.9741\n","Training epoch 18:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:11<00:00,  2.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 18.3392\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.4341\n","F1s: [0.83091787 0.95473251 0.91549296 0.97674419 0.9258312  0.72727273\n"," 0.82894737 0.8375     0.66666667]\n","Avg F1: 0.8516\n","AUCs: [0.97680385 0.98891484 0.99627309 0.9911825  0.98212727 0.96443887\n"," 0.97026145 0.97994919 0.95446429]\n","Avg AUC: 0.9783\n","Training epoch 19:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:11<00:00,  2.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 17.2692\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:10<00:00,  4.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.4174\n","F1s: [0.8358209  0.9382716  0.92       0.97674419 0.91262136 0.70967742\n"," 0.81578947 0.83832335 0.57142857]\n","Avg F1: 0.8354\n","AUCs: [0.97646299 0.98440293 0.99732486 0.99801777 0.98272996 0.95460874\n"," 0.96918125 0.97166308 0.94513889]\n","Avg AUC: 0.9755\n","Training epoch 20:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:14<00:00,  2.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 15.1244\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.4112\n","F1s: [0.84210526 0.96694215 0.92753623 1.         0.92230576 0.71428571\n"," 0.82089552 0.8625     0.6       ]\n","Avg F1: 0.8507\n","AUCs: [0.98329805 0.98914548 0.99718767 1.         0.98168045 0.96313005\n"," 0.96263392 0.97586476 0.94375   ]\n","Avg AUC: 0.9774\n","Training epoch 21:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:14<00:00,  2.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 13.5854\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:10<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.6322\n","F1s: [0.82857143 0.97142857 0.93877551 0.97674419 0.92462312 0.69026549\n"," 0.83333333 0.86060606 0.75      ]\n","Avg F1: 0.8638\n","Training epoch 22:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:14<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 12.5977\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:08<00:00,  5.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.2504\n","F1s: [0.84263959 0.9626556  0.93706294 0.97674419 0.92307692 0.75757576\n"," 0.8137931  0.86046512 0.59459459]\n","Avg F1: 0.8521\n","AUCs: [0.98202433 0.98496512 0.99679898 0.99945318 0.97934245 0.9652186\n"," 0.9633614  0.97273793 0.93422619]\n","Avg AUC: 0.9753\n","Training epoch 23:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:14<00:00,  2.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 11.0349\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:08<00:00,  4.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.8065\n","F1s: [0.85106383 0.96296296 0.92413793 0.97674419 0.91400491 0.72307692\n"," 0.83687943 0.82840237 0.65      ]\n","Avg F1: 0.8519\n","AUCs: [0.97814933 0.98784812 0.99711908 0.99357485 0.9804543  0.94566973\n"," 0.96466205 0.97181943 0.95357143]\n","Avg AUC: 0.9748\n","Training epoch 24:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 9.9454\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.9251\n","F1s: [0.82722513 0.96296296 0.91156463 0.97674419 0.91811414 0.73333333\n"," 0.83211679 0.84337349 0.52380952]\n","Avg F1: 0.8366\n","AUCs: [0.9788131  0.98959234 0.99727913 0.99897471 0.97968536 0.9539961\n"," 0.96274415 0.97398867 0.9422619 ]\n","Avg AUC: 0.9753\n","Training epoch 25:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 9.1423\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:08<00:00,  5.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.2457\n","F1s: [0.85148515 0.94468085 0.92413793 0.97674419 0.9280397  0.6779661\n"," 0.80519481 0.85549133 0.54054054]\n","Avg F1: 0.8338\n","AUCs: [0.97500987 0.98989506 0.99657033 0.99945318 0.98324951 0.95836814\n"," 0.96635951 0.97924565 0.91865079]\n","Avg AUC: 0.9741\n","Training epoch 26:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:11<00:00,  2.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 7.8006\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.2374\n","F1s: [0.84693878 0.95081967 0.91156463 0.97674419 0.92345679 0.70921986\n"," 0.82119205 0.85542169 0.53333333]\n","Avg F1: 0.8365\n","AUCs: [0.98087618 0.99055815 0.99716481 0.99986329 0.98394572 0.94572542\n"," 0.96305278 0.97338284 0.93204365]\n","Avg AUC: 0.9741\n","Training epoch 27:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:14<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 7.4133\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.3056\n","F1s: [0.79381443 0.95901639 0.92413793 0.97674419 0.92346939 0.65625\n"," 0.80882353 0.8452381  0.5       ]\n","Avg F1: 0.8208\n","AUCs: [0.96603997 0.9865796  0.99675325 0.99890636 0.98271956 0.94876079\n"," 0.96378026 0.97383232 0.92559524]\n","Avg AUC: 0.9714\n","Training epoch 28:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 7.3307\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.7652\n","F1s: [0.8241206  0.9626556  0.94285714 0.97674419 0.92086331 0.71666667\n"," 0.83098592 0.8700565  0.5       ]\n","Avg F1: 0.8383\n","AUCs: [0.97915396 0.98812201 0.99810225 0.99965824 0.98086994 0.95625174\n"," 0.95403642 0.97637287 0.92867063]\n","Avg AUC: 0.9735\n","Training epoch 29:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.2573\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:10<00:00,  4.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.7616\n","F1s: [0.81632653 0.95435685 0.92517007 0.97674419 0.90862944 0.71544715\n"," 0.81944444 0.88636364 0.55172414]\n","Avg F1: 0.8394\n","AUCs: [0.97140397 0.98799227 0.99647887 0.99972659 0.97944636 0.95232526\n"," 0.96159781 0.9791284  0.93115079]\n","Avg AUC: 0.9733\n","Training epoch 30:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 7.1066\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.9260\n","F1s: [0.85561497 0.96296296 0.93706294 1.         0.90862944 0.71317829\n"," 0.83453237 0.86363636 0.61538462]\n","Avg F1: 0.8546\n","AUCs: [0.97800581 0.98727152 0.9979422  1.         0.97684858 0.94842662\n"," 0.96117896 0.97213211 0.93809524]\n","Avg AUC: 0.9733\n","Training epoch 31:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:12<00:00,  2.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.2227\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.2088\n","F1s: [0.82978723 0.9539749  0.92753623 0.97674419 0.92345679 0.74015748\n"," 0.81481481 0.78021978 0.68965517]\n","Avg F1: 0.8485\n","AUCs: [0.97834667 0.98940495 0.99657033 0.99993165 0.9820961  0.95148984\n"," 0.96157577 0.9627907  0.92113095]\n","Avg AUC: 0.9715\n","Training epoch 32:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.0923\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:10<00:00,  4.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.4393\n","F1s: [0.85714286 0.96326531 0.94444444 0.97674419 0.91919192 0.71111111\n"," 0.82014388 0.86390533 0.66666667]\n","Avg F1: 0.8581\n","AUCs: [0.97719852 0.9925186  0.99823944 0.9987013  0.98210649 0.94747981\n"," 0.9648825  0.97672464 0.94037698]\n","Avg AUC: 0.9754\n","Training epoch 33:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.2736\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.9075\n","F1s: [0.82857143 0.91139241 0.92198582 0.97674419 0.91959799 0.7107438\n"," 0.81081081 0.86549708 0.46153846]\n","Avg F1: 0.8230\n","AUCs: [0.9760145  0.98879952 0.99693616 0.99719754 0.98230392 0.93389028\n"," 0.95764076 0.98231386 0.9046627 ]\n","Avg AUC: 0.9689\n","Training epoch 34:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.9068\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.3398\n","F1s: [0.82291667 0.97119342 0.93617021 0.97674419 0.92156863 0.71428571\n"," 0.81481481 0.84153005 0.4516129 ]\n","Avg F1: 0.8279\n","AUCs: [0.97497399 0.98908782 0.99746204 0.99938483 0.98159732 0.95689223\n"," 0.94768749 0.9729529  0.91071429]\n","Avg AUC: 0.9701\n","Training epoch 35:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.2017\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.3977\n","F1s: [0.83809524 0.95934959 0.92753623 0.97674419 0.93401015 0.7047619\n"," 0.81818182 0.88095238 0.56410256]\n","Avg F1: 0.8449\n","AUCs: [0.98265222 0.98902295 0.99741632 0.99876965 0.98441332 0.94625453\n"," 0.96157577 0.98014462 0.91765873]\n","Avg AUC: 0.9731\n","Training epoch 36:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.8873\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:10<00:00,  4.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.2844\n","F1s: [0.82926829 0.96356275 0.94202899 0.97674419 0.92079208 0.703125\n"," 0.80597015 0.83018868 0.54054054]\n","Avg F1: 0.8347\n","AUCs: [0.97675003 0.98453266 0.99709621 0.99897471 0.97986201 0.94232804\n"," 0.95833517 0.97473129 0.91121032]\n","Avg AUC: 0.9693\n","Training epoch 37:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:11<00:00,  2.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 4.7418\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.2076\n","F1s: [0.84158416 0.96747967 0.93055556 0.97674419 0.92620865 0.75409836\n"," 0.82089552 0.86746988 0.43902439]\n","Avg F1: 0.8360\n","AUCs: [0.97630153 0.98895808 0.99757637 0.99972659 0.98377946 0.95263158\n"," 0.95882016 0.97889388 0.91815476]\n","Avg AUC: 0.9728\n","Training epoch 38:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:12<00:00,  2.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 2.5826\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:09<00:00,  4.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 5.9456\n","F1s: [0.84466019 0.96747967 0.95714286 1.         0.9280397  0.73333333\n"," 0.81118881 0.83636364 0.5625    ]\n","Avg F1: 0.8490\n","AUCs: [0.97804169 0.99002479 0.99851381 1.         0.98398728 0.9481203\n"," 0.96521317 0.97701778 0.93244048]\n","Avg AUC: 0.9748\n","Training epoch 39:\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 344/344 [02:13<00:00,  2.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 3.2443\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 43/43 [00:07<00:00,  5.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 6.2399\n","F1s: [0.83937824 0.96666667 0.92       0.97777778 0.91707317 0.74782609\n"," 0.81632653 0.85365854 0.5       ]\n","Avg F1: 0.8376\n","AUCs: [0.98064296 0.98914548 0.99677611 0.99993165 0.98086994 0.95157338\n"," 0.96327322 0.97699824 0.92490079]\n","Avg AUC: 0.9738\n"]}],"source":["%run \"main.py\" --data-dir \"data/cpsc_processed\" --use-gpu"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"KI4HkmwcBD9o","outputId":"31995817-d956-4ffa-d38e-c41be6c4cb08"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 0:\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1392 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","  9%|▉         | 131/1392 [59:39<9:40:36, 27.63s/it]"]}],"source":["%run \"main.py\" --data-dir \"data/train_dataset\"\n","# --use-gpu"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
