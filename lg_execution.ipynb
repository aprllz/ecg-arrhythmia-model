{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for: control data preprocessing and model training, testing, and evaluation\n",
    "# Dataset: data/cpsc_processed: \n",
    "\n",
    "# Dataset: data/op_09_classes/:\n",
    "# - training/evaluation:\n",
    "# - testing:\n",
    "\n",
    "# Dataset: data/op_08_classes (without PVC class in testing data)\n",
    "# - training/evaluation:\n",
    "# - testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for cpsc_processed:\n",
    "\n",
    "#perform preprocessing,baseline on data/cpsc_processed\n",
    "%run \"preprocess.py\" --data-dir \"data/cpsc_processed\" \n",
    "%run \"baselines.py\" --data-dir \"data/cpsc_processed\" --classifier 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for op_09_classes:\n",
    "\n",
    "#perform preprocessing,baseline on the data, op_9_classes\n",
    "%run \"preprocess.py\" --data-dir \"data/op_09_classes/train_dataset\" \n",
    "%run \"preprocess.py\" --data-dir \"data/op_09_classes/test_dataset\"\n",
    "\n",
    "#perform baseline training on the data, op_9_classes\n",
    "%run \"baselines.py\" --data-dir \"data/op_09_classes/train_dataset\" --classifier 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#prepare data for op_08_classes:\n",
    "#reset csv files\n",
    "\n",
    "#path to training data and testing data\n",
    "train_data_dir = \"data/op_08_classes/train_dataset\"\n",
    "test_data_dir = \"data/op_08_classes/test_dataset\"\n",
    "\n",
    "#count existing .csv files in the training data and testing data\n",
    "!ls $train_data_dir/*.csv | wc -l\n",
    "!ls $test_data_dir/*.csv | wc -l\n",
    "\n",
    "#delete all existing .csv files in the training data \n",
    "!rm -rf $train_data_dir/*.csv\n",
    "#delete all existing .csv files in the testing data\n",
    "!rm -rf $test_data_dir/*.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/op_08_classes/train_dataset/labels.csv\n",
      "Generating expert features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27823 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27823/27823 [43:37<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training LR...\n",
      "Finding optimal thresholds on validation dataset...\n",
      "LR F1s: [np.float64(0.9191251271617498), np.float64(0.61), np.float64(0.2242562929061785), np.float64(0.7887323943661971), np.float64(0.8015267175572519), np.float64(0.2), np.float64(0.35452793834296725), np.float64(0.17777777777777778)]\n",
      "Avg F1: 0.5094932810140153\n",
      "Start training RF...\n",
      "Finding optimal thresholds on validation dataset...\n",
      "RF F1s: [np.float64(0.9316493313521546), np.float64(0.6151012891344383), np.float64(0.31868131868131866), np.float64(0.8529411764705882), np.float64(0.8282442748091603), np.float64(0.14393939393939395), np.float64(0.41839080459770117), np.float64(0.46153846153846156)]\n",
      "Avg F1: 0.5713107563154021\n",
      "Start training LGB...\n",
      "[LightGBM] [Info] Number of positive: 15134, number of negative: 7123\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.679966 -> initscore=0.753615\n",
      "[LightGBM] [Info] Start training from score 0.753615\n",
      "[LightGBM] [Info] Number of positive: 2330, number of negative: 19927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.104686 -> initscore=-2.146207\n",
      "[LightGBM] [Info] Start training from score -2.146207\n",
      "[LightGBM] [Info] Number of positive: 1312, number of negative: 20945\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058948 -> initscore=-2.770347\n",
      "[LightGBM] [Info] Start training from score -2.770347\n",
      "[LightGBM] [Info] Number of positive: 668, number of negative: 21589\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030013 -> initscore=-3.475651\n",
      "[LightGBM] [Info] Start training from score -3.475651\n",
      "[LightGBM] [Info] Number of positive: 1995, number of negative: 20262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089635 -> initscore=-2.318103\n",
      "[LightGBM] [Info] Start training from score -2.318103\n",
      "[LightGBM] [Info] Number of positive: 1037, number of negative: 21220\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046592 -> initscore=-3.018612\n",
      "[LightGBM] [Info] Start training from score -3.018612\n",
      "[LightGBM] [Info] Number of positive: 1587, number of negative: 20670\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.071303 -> initscore=-2.566838\n",
      "[LightGBM] [Info] Start training from score -2.566838\n",
      "[LightGBM] [Info] Number of positive: 263, number of negative: 21994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22257, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011817 -> initscore=-4.426371\n",
      "[LightGBM] [Info] Start training from score -4.426371\n",
      "Finding optimal thresholds on validation dataset...\n",
      "LGB F1s: [np.float64(0.9399699849924963), np.float64(0.6911196911196911), np.float64(0.31529411764705884), np.float64(0.8444444444444444), np.float64(0.8576512455516014), np.float64(0.20161290322580644), np.float64(0.4954545454545455), np.float64(0.4)]\n",
      "Avg F1: 0.5931933665544555\n",
      "Start training MLP...\n",
      "Finding optimal thresholds on validation dataset...\n",
      "MLP F1s: [np.float64(0.928388746803069), np.float64(0.627151051625239), np.float64(0.3254237288135593), np.float64(0.8029197080291971), np.float64(0.8100358422939068), np.float64(0.17100371747211895), np.float64(0.43169398907103823), np.float64(0.22857142857142856)]\n",
      "Avg F1: 0.5406485265849446\n"
     ]
    }
   ],
   "source": [
    "#prepare data for op_08_classes:\n",
    "\n",
    "#perform preprocessing,baseline on the data, op_08_classes\n",
    "%run \"preprocess.py\" --data-dir \"data/op_08_classes/train_dataset\" --num-classes 8\n",
    "%run \"preprocess.py\" --data-dir \"data/op_08_classes/test_dataset\" --num-classes 8\n",
    "\n",
    "#perform baseline training on the data, op_08_classes\n",
    "%run \"baselines.py\" --data-dir \"data/op_08_classes/train_dataset\" --classifier 'all' --num-classes 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cpsc_processed/labels_8_classes.csv\n",
      "Generating expert features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6877/6877 [12:00<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training LR...\n",
      "Finding optimal thresholds on validation dataset...\n",
      "LR F1s: [np.float64(0.5137614678899083), np.float64(0.6058823529411764), np.float64(0.3463203463203463), np.float64(0.6976744186046512), np.float64(0.8663366336633663), np.float64(0.25609756097560976), np.float64(0.5612244897959183), np.float64(0.22641509433962265)]\n",
      "Avg F1: 0.509214045566325\n",
      "Start training RF...\n",
      "Finding optimal thresholds on validation dataset...\n",
      "RF F1s: [np.float64(0.5609756097560976), np.float64(0.6586102719033232), np.float64(0.3541666666666667), np.float64(0.8085106382978723), np.float64(0.8388746803069054), np.float64(0.3026315789473684), np.float64(0.6057142857142858), np.float64(0.47058823529411764)]\n",
      "Avg F1: 0.5750089958608297\n",
      "Start training LGB...\n",
      "[LightGBM] [Info] Number of positive: 730, number of negative: 4773\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 160254\n",
      "[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.132655 -> initscore=-1.877686\n",
      "[LightGBM] [Info] Start training from score -1.877686\n",
      "[LightGBM] [Info] Number of positive: 980, number of negative: 4523\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 160254\n",
      "[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.178085 -> initscore=-1.529378\n",
      "[LightGBM] [Info] Start training from score -1.529378\n",
      "[LightGBM] [Info] Number of positive: 570, number of negative: 4933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 160254\n",
      "[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.103580 -> initscore=-2.158066\n",
      "[LightGBM] [Info] Start training from score -2.158066\n",
      "[LightGBM] [Info] Number of positive: 192, number of negative: 5311\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 160254\n",
      "[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034890 -> initscore=-3.320040\n",
      "[LightGBM] [Info] Start training from score -3.320040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1468, number of negative: 4035\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 160254\n",
      "[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.266764 -> initscore=-1.011105\n",
      "[LightGBM] [Info] Start training from score -1.011105\n",
      "[LightGBM] [Info] Number of positive: 501, number of negative: 5002\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 160254\n",
      "[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.091041 -> initscore=-2.300987\n",
      "[LightGBM] [Info] Start training from score -2.300987\n",
      "[LightGBM] [Info] Number of positive: 710, number of negative: 4793\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 160254\n",
      "[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129021 -> initscore=-1.909647\n",
      "[LightGBM] [Info] Start training from score -1.909647\n",
      "[LightGBM] [Info] Number of positive: 175, number of negative: 5328\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 160254\n",
      "[LightGBM] [Info] Number of data points in the train set: 5503, number of used features: 636\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031801 -> initscore=-3.415945\n",
      "[LightGBM] [Info] Start training from score -3.415945\n",
      "Finding optimal thresholds on validation dataset...\n",
      "LGB F1s: [np.float64(0.6162162162162163), np.float64(0.7761194029850746), np.float64(0.36231884057971014), np.float64(0.8163265306122449), np.float64(0.8939393939393939), np.float64(0.3184713375796178), np.float64(0.7058823529411765), np.float64(0.5777777777777777)]\n",
      "Avg F1: 0.6333814815789015\n",
      "Start training MLP...\n",
      "Finding optimal thresholds on validation dataset...\n",
      "MLP F1s: [np.float64(0.5698324022346368), np.float64(0.6785714285714286), np.float64(0.41284403669724773), np.float64(0.8163265306122449), np.float64(0.8777777777777778), np.float64(0.3076923076923077), np.float64(0.593939393939394), np.float64(0.36363636363636365)]\n",
      "Avg F1: 0.5775775301451751\n"
     ]
    }
   ],
   "source": [
    "#prepare data for cpsc_processed FOR (8 classes):\n",
    "\n",
    "#perform preprocessing,baseline on the data, cpsc_processed\n",
    "%run \"preprocess.py\" --data-dir \"data/cpsc_processed\" --num-classes 8\n",
    "\n",
    "\n",
    "#perform baseline training on the data, cpsc_processed\n",
    "%run \"baselines.py\" --data-dir \"data/cpsc_processed\" --classifier 'all' --num-classes 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model, using train data: data/cpsc_processed, with full 09 classes:\n",
    "%run \"main.py\" --data-dir \"data/cpsc_processed\" --epochs 1 --num-workers 2 --batch-size 8 --num-classes 9\n",
    "#Train model, using train data: data/cpsc_processed, with only 08 classes:\n",
    "%run \"main.py\" --data-dir \"data/cpsc_processed\" --epochs 1 --num-workers 2 --batch-size 8 --num-classes 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
